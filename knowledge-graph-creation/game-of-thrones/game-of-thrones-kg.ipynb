{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expanding the knowledge\n",
    "\n",
    "Let's say that now we want to expand our existing knowledge graph with\n",
    "additional information to enrich the dataset, provide more context and retrieve\n",
    "more relevant data. \n",
    "\n",
    "In this example, we will take **unstructured data**, such as the\n",
    "character description summary provided below, extract entities from that\n",
    "summary, generate triplets to build the knowledge graph create queries and\n",
    "eventually execute those queries in Memgraph to incorporate with the existing\n",
    "graph. \n",
    "\n",
    "\n",
    "This highlights the possibility of loading an unstructured data into the Memgraph. \n",
    "\n",
    "Here is an example of unstructured data: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample text summary for processing\n",
    "summary = \"\"\"\n",
    "    Viserys Targaryen is the last living son of the former king, Aerys II Targaryen (the 'Mad King').\n",
    "    As one of the last known Targaryen heirs, Viserys Targaryen is obsessed with reclaiming the Iron Throne and \n",
    "    restoring his family’s rule over Westeros. Ambitious and arrogant, he often treats his younger sister, Daenerys Targaryen, \n",
    "    as a pawn, seeing her only as a means to gain power. His ruthless ambition leads him to make a marriage alliance with \n",
    "    Khal Drogo, a powerful Dothraki warlord, hoping Khal Drogo will give him the army he needs. \n",
    "    However, Viserys Targaryen’s impatience and disrespect toward the Dothraki culture lead to his downfall;\n",
    "    he is ultimately killed by Khal Drogo in a brutal display of 'a crown for a king' – having molten gold poured over his head. \n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entity extraction\n",
    "\n",
    "The first step in the process is to extract entities from the summary using\n",
    "[SpaCy’s LLM](https://spacy.io/usage/large-language-models).\n",
    "\n",
    "To begin, we need to install SpaCy and the specific model we wll be using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install spacy\n",
    "%pip install spacy_llm\n",
    "!python -m spacy download en_core_web_md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are extracting entities from the text, that is, preprocessing the data before\n",
    "sending it to the GPT model, to get more accurate and relevant results. By\n",
    "using SpaCy, we can identify key entities such as characters and locations\n",
    "for a better understanding of the semantics in the text.\n",
    "\n",
    "This is useful because SpaCy is specifically trained to recognize\n",
    "linguistic patterns and relationships in text, which helps to isolate and\n",
    "highlight the most important pieces of information. By preprocessing the text\n",
    "this way, we ensure that the GPT model receives a more structured input, helps\n",
    "reduce noise and irrelevant data, leading to more precise and context-aware\n",
    "outputs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import spacy\n",
    "from spacy_llm.util import assemble\n",
    "import json\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "\n",
    "# Split document into sentences\n",
    "def split_document_sent(text, nlp):\n",
    "    doc = nlp(text)\n",
    "    return [sent.text.strip() for sent in doc.sents]\n",
    "\n",
    "\n",
    "def process_text(text, nlp, verbose=False):\n",
    "    doc = nlp(text)\n",
    "    if verbose:\n",
    "        print(f\"Text: {doc.text}\")\n",
    "        print(f\"Entities: {[(ent.text, ent.label_) for ent in doc.ents]}\")\n",
    "    return doc\n",
    "\n",
    "\n",
    "# Pipeline to run entity extraction\n",
    "def extract_entities(text, nlp, verbose=False):\n",
    "    processed_data = []\n",
    "    entity_counts = Counter()\n",
    "\n",
    "    sentences = split_document_sent(text, nlp)\n",
    "    for sent in sentences:\n",
    "        doc = process_text(sent, nlp, verbose)\n",
    "        entities = [(ent.text, ent.label_) for ent in doc.ents]\n",
    "\n",
    "        # Store processed data for each sentence\n",
    "        processed_data.append({\"text\": doc.text, \"entities\": entities})\n",
    "\n",
    "        # Update counters\n",
    "        entity_counts.update([ent[1] for ent in entities])\n",
    "\n",
    "    # Export to JSON\n",
    "    with open(\"processed_data.json\", \"w\") as f:\n",
    "        json.dump(processed_data, f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate queries\n",
    "\n",
    "After the spacyLLM has pre-processed the entities, the data is passed to the GPT model to generate structured data consisting of nodes and relationships. From that, we generate the Cypher queries which will be executed in Memgraph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_cypher_queries(nodes, relationships):\n",
    "    queries = []\n",
    "\n",
    "    # Create nodes\n",
    "    for node in nodes:\n",
    "        query = f\"\"\"\n",
    "        MERGE (n:{node['type']}:Entity {{name: '{node['name']}'}}) \n",
    "        ON CREATE SET n.id={node['id']} \n",
    "        ON MATCH SET n.id={node['id']}\n",
    "        \"\"\"\n",
    "        queries.append(query)\n",
    "\n",
    "    # Create relationships\n",
    "    for rel in relationships:\n",
    "        query = f\"MATCH (a {{id: {rel['source']}}}), (b {{id: {rel['target']}}}) \" \\\n",
    "                f\"CREATE (a)-[:{rel['relationship']}]->(b)\"\n",
    "        queries.append(query)\n",
    "\n",
    "    return queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enriching the graph\n",
    "\n",
    "The `enrich_graph_data` function will merge new knowledge into the graph by doing the following:\n",
    "\n",
    "1. Extracting the entities with SpacyLLM into JSON\n",
    "2. Creating nodes and relationships based on extracted entities with GPT model\n",
    "3. Loading data into Memgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "def enrich_graph_data(driver, summary):\n",
    "    nest_asyncio.apply()\n",
    "    \n",
    "    load_dotenv()\n",
    "    os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "    client = AsyncOpenAI()\n",
    "\n",
    "    # Load the spaCy model\n",
    "    nlp = spacy.load(\"en_core_web_md\")\n",
    "\n",
    "    # Sample text summary for processing\n",
    "    summary = \"\"\"\n",
    "        Viserys Targaryen is the last living son of the former king, Aerys II Targaryen (the 'Mad King').\n",
    "        As one of the last known Targaryen heirs, Viserys Targaryen is obsessed with reclaiming the Iron Throne and \n",
    "        restoring his family’s rule over Westeros. Ambitious and arrogant, he often treats his younger sister, Daenerys Targaryen, \n",
    "        as a pawn, seeing her only as a means to gain power. His ruthless ambition leads him to make a marriage alliance with \n",
    "        Khal Drogo, a powerful Dothraki warlord, hoping Khal Drogo will give him the army he needs. \n",
    "        However, Viserys Targaryen’s impatience and disrespect toward the Dothraki culture lead to his downfall;\n",
    "        he is ultimately killed by Khal Drogo in a brutal display of 'a crown for a king' – having molten gold poured over his head. \n",
    "    \"\"\"\n",
    "\n",
    "    extract_entities(summary, nlp)\n",
    "\n",
    "    # Load processed data from JSON\n",
    "    json_path = Path(\"processed_data.json\")\n",
    "    with open(json_path, \"r\") as f:\n",
    "        processed_data = json.load(f)\n",
    "\n",
    "    # Prepare nodes and relationships\n",
    "    nodes = []\n",
    "    relationships = []\n",
    "\n",
    "    # Formulate a prompt for GPT-4\n",
    "    prompt = (\n",
    "        \"Extract entities and relationships from the following JSON data. For each entry in data['entities'], \"\n",
    "        \"create a 'node' dictionary with fields 'id' (unique identifier), 'name' (entity text), and 'type' (entity label). \"\n",
    "        \"For entities that have meaningful connections, define 'relationships' as dictionaries with 'source' (source node id), \"\n",
    "        \"'target' (target node id), and 'relationship' (type of connection). Create max 30 nodes, format relationships in the format of capital letters and _ inbetween words and format the entire response in the JSON output containing only variables nodes and relationships without any text inbetween. Use following labels for nodes: Character, Title, Location, House, Death, Event, Allegiance and following relationship types: HAPPENED_IN, SIBLING_OF, PARENT_OF, MARRIED_TO, HEALED_BY, RULES, KILLED, LOYAL_TO, BETRAYED_BY. Make sure the entire JSON file fits in the output\"\n",
    "        \"JSON data:\\n\"\n",
    "        f\"{json.dumps(processed_data)}\"\n",
    "    )\n",
    "\n",
    "    response = asyncio.run(get_response(client, prompt))\n",
    "\n",
    "    structured_data = json.loads(response)  # Assuming GPT-4 outputs structured JSON\n",
    "\n",
    "    # Populate nodes and relationships lists\n",
    "    nodes.extend(structured_data.get(\"nodes\", []))\n",
    "    relationships.extend(structured_data.get(\"relationships\", []))\n",
    "\n",
    "    cypher_queries = generate_cypher_queries(nodes, relationships)\n",
    "    with driver.session() as session:\n",
    "        for query in cypher_queries:\n",
    "            try:\n",
    "                session.run(query)\n",
    "                print(f\"Executed query: {query}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error executing query: {query}. Error: {e}\")\n",
    "\n",
    "\n",
    "enrich_graph_data(driver, summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The knowledge graph now has additional knowledge, that is being enriched from unstructured text. "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
