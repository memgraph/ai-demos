{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "679506f4",
   "metadata": {},
   "source": [
    "# LightRAG with Memgraph Integration Demo\n",
    "\n",
    "This notebook demonstrates how to use LightRAG with Memgraph as the graph storage backend. LightRAG is a simple and fast retrieval-augmented generation framework that combines the power of graph databases with large language models.\n",
    "\n",
    "## What you'll learn:\n",
    "- How to set up LightRAG with Memgraph\n",
    "- How to insert documents and create knowledge graphs\n",
    "- How to perform different types of queries (local, global, hybrid)\n",
    "\n",
    "## Prerequisites:\n",
    "- Memgraph running (Docker: `docker run -p 7687:7687 memgraph/memgraph:latest`)\n",
    "- OpenAI API key\n",
    "- Required Python packages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77eb238f",
   "metadata": {},
   "source": [
    "## Installation and Setup\n",
    "\n",
    "First, let's install the required packages. LightRAG with Memgraph support needs to be installed from source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affd166b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone LightRAG repository and install from source (required for Memgraph support)\n",
    "import os\n",
    "\n",
    "# Clone the repository (only if it doesn't exist)\n",
    "if not os.path.exists('LightRAG'):\n",
    "    print(\"Cloning LightRAG repository...\")\n",
    "    !git clone https://github.com/HKUDS/LightRAG.git\n",
    "else:\n",
    "    print(\"LightRAG directory already exists, skipping clone...\")\n",
    "\n",
    "# Install LightRAG from the cloned directory\n",
    "print(\"Installing LightRAG in editable mode...\")\n",
    "%pip install -e ./LightRAG\n",
    "\n",
    "print(\"‚úÖ LightRAG and dependencies installed successfully!\")\n",
    "print(\"‚ö†Ô∏è  Note: You may need to restart the kernel if imports don't work immediately.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "698da773",
   "metadata": {},
   "source": [
    "## Environment Configuration\n",
    "\n",
    "Set up your environment variables for Memgraph connection and OpenAI API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1006c47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import getpass\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Set up OpenAI API key\n",
    "if not os.getenv(\"OPENAI_API_KEY\"):\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API key: \")\n",
    "\n",
    "# Configure Memgraph connection\n",
    "os.environ[\"MEMGRAPH_URI\"] = \"bolt://localhost:7687\"\n",
    "os.environ[\"MEMGRAPH_USERNAME\"] = \"\"  # Default is empty\n",
    "os.environ[\"MEMGRAPH_PASSWORD\"] = \"\"  # Default is empty\n",
    "os.environ[\"MEMGRAPH_DATABASE\"] = \"memgraph\"  # Default database name\n",
    "os.environ[\"MEMGRAPH_WORKSPACE\"] = \"lightrag_demo\"  # Workspace for data isolation\n",
    "\n",
    "print(\"Environment configured successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "722b489f",
   "metadata": {},
   "source": [
    "## Import Required Libraries\n",
    "\n",
    "**Important**: If you just ran the installation cell above, please restart the kernel first.\n",
    "\n",
    "Import all necessary libraries for LightRAG with Memgraph integration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3670b18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightrag import LightRAG, QueryParam\n",
    "from lightrag.llm.openai import gpt_4o_mini_complete, openai_embed\n",
    "from lightrag.kg.shared_storage import initialize_pipeline_status\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ecd9686",
   "metadata": {},
   "source": [
    "## Initialize LightRAG with Memgraph\n",
    "\n",
    "Create and configure a LightRAG instance using Memgraph as the graph storage backend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e49c73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working directory for LightRAG storage\n",
    "WORKING_DIR = \"./lightrag_memgraph_storage\"\n",
    "if not os.path.exists(WORKING_DIR):\n",
    "    os.mkdir(WORKING_DIR)\n",
    "\n",
    "async def initialize_rag():\n",
    "    \"\"\"Initialize LightRAG with Memgraph as graph storage.\"\"\"\n",
    "    rag = LightRAG(\n",
    "        working_dir=WORKING_DIR,\n",
    "        embedding_func=openai_embed,\n",
    "        llm_model_func=gpt_4o_mini_complete,\n",
    "        graph_storage=\"MemgraphStorage\",  # Use Memgraph as graph storage\n",
    "    )\n",
    "    \n",
    "    await rag.initialize_storages()  # Initialize storage backends\n",
    "    await initialize_pipeline_status()  # Initialize processing pipeline\n",
    "    \n",
    "    return rag\n",
    "\n",
    "# Initialize RAG instance\n",
    "rag = await initialize_rag()\n",
    "print(\"LightRAG initialized with Memgraph successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36635c60",
   "metadata": {},
   "source": [
    "## Sample Data: AI and Machine Learning Text\n",
    "\n",
    "Let's create some sample text about artificial intelligence and machine learning to demonstrate the knowledge graph creation capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0bfd9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample text about AI and Machine Learning\n",
    "ai_ml_text = \"\"\"\n",
    "Artificial Intelligence (AI) is a broad field of computer science that aims to create intelligent machines \n",
    "capable of performing tasks that typically require human intelligence. Machine Learning (ML) is a subset of \n",
    "AI that focuses on the development of algorithms and statistical models that enable computers to improve \n",
    "their performance on a specific task through experience.\n",
    "\n",
    "Deep Learning is a specialized branch of Machine Learning that uses neural networks with multiple layers \n",
    "to model and understand complex patterns in data. Convolutional Neural Networks (CNNs) are particularly \n",
    "effective for image recognition tasks, while Recurrent Neural Networks (RNNs) excel at processing \n",
    "sequential data like natural language.\n",
    "\n",
    "Natural Language Processing (NLP) is another important subfield of AI that deals with the interaction \n",
    "between computers and human language. Large Language Models (LLMs) like GPT and BERT have revolutionized \n",
    "NLP by demonstrating remarkable capabilities in text generation, translation, and understanding.\n",
    "\n",
    "Knowledge Graphs are structured representations of information that capture entities and their relationships. \n",
    "They are widely used in AI systems to store and reason about complex domain knowledge. Graph databases \n",
    "like Neo4j and Memgraph provide efficient storage and querying capabilities for knowledge graphs.\n",
    "\n",
    "Retrieval-Augmented Generation (RAG) is a technique that combines the power of large language models \n",
    "with external knowledge retrieval systems. RAG systems can access up-to-date information from knowledge \n",
    "bases to generate more accurate and contextually relevant responses.\n",
    "\"\"\"\n",
    "\n",
    "print(\"Sample text prepared for knowledge graph creation.\")\n",
    "print(f\"Text length: {len(ai_ml_text)} characters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55de516",
   "metadata": {},
   "source": [
    "## Insert Documents and Create Knowledge Graph\n",
    "\n",
    "Now let's insert the sample text into LightRAG. This will automatically extract entities and relationships to create a knowledge graph stored in Memgraph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10c23b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert the text into LightRAG\n",
    "print(\"Inserting text and creating knowledge graph...\")\n",
    "\n",
    "try:\n",
    "    await rag.ainsert(ai_ml_text)\n",
    "    print(\"‚úÖ Knowledge graph created successfully!\")\n",
    "    print(\"The extracted entities and relationships are now stored in Memgraph.\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error during insertion: {e}\")\n",
    "    print(\"Please check your Memgraph connection and OpenAI API key.\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9342b5f0",
   "metadata": {},
   "source": [
    "## Query the Knowledge Graph\n",
    "\n",
    "Let's demonstrate different types of queries that LightRAG supports:\n",
    "\n",
    "- **Local mode**: Focuses on context-dependent information\n",
    "- **Global mode**: Utilizes global knowledge\n",
    "- **Hybrid mode**: Combines local and global retrieval methods\n",
    "- **Mix mode**: Integrates knowledge graph and vector retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3bc0b96",
   "metadata": {},
   "source": [
    "### Local Query\n",
    "Local queries focus on specific entities and their immediate relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2398cfb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local query - focuses on specific entities and their immediate context\n",
    "local_query = \"What is Deep Learning and how does it relate to Machine Learning?\"\n",
    "\n",
    "print(f\"üîç Local Query: {local_query}\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "try:\n",
    "    local_response = await rag.aquery(\n",
    "        local_query,\n",
    "        param=QueryParam(mode=\"local\")\n",
    "    )\n",
    "    print(local_response)\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error during local query: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4e1196",
   "metadata": {},
   "source": [
    "### Global Query\n",
    "Global queries utilize broader knowledge patterns across the entire knowledge graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a54af4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global query - uses broader knowledge patterns\n",
    "global_query = \"What are the main components and technologies in the AI ecosystem?\"\n",
    "\n",
    "print(f\"üåê Global Query: {global_query}\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "try:\n",
    "    global_response = await rag.aquery(\n",
    "        global_query,\n",
    "        param=QueryParam(mode=\"global\")\n",
    "    )\n",
    "    print(global_response)\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error during global query: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a125eafb",
   "metadata": {},
   "source": [
    "### Hybrid Query\n",
    "Hybrid queries combine both local and global retrieval methods for comprehensive answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67d3662",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hybrid query - combines local and global methods\n",
    "hybrid_query = \"How do Knowledge Graphs and RAG systems work together in AI applications?\"\n",
    "\n",
    "print(f\"üîÑ Hybrid Query: {hybrid_query}\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "try:\n",
    "    hybrid_response = await rag.aquery(\n",
    "        hybrid_query,\n",
    "        param=QueryParam(mode=\"hybrid\")\n",
    "    )\n",
    "    print(hybrid_response)\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error during hybrid query: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e945511e",
   "metadata": {},
   "source": [
    "### Mix Query\n",
    "Mix queries integrate knowledge graph and vector retrieval for enhanced performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052b9507",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mix query - integrates knowledge graph and vector retrieval\n",
    "mix_query = \"Compare CNNs and RNNs in terms of their applications and architectures.\"\n",
    "\n",
    "print(f\"üîÄ Mix Query: {mix_query}\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "try:\n",
    "    mix_response = await rag.aquery(\n",
    "        mix_query,\n",
    "        param=QueryParam(mode=\"mix\")\n",
    "    )\n",
    "    print(mix_response)\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error during mix query: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4aeb33d",
   "metadata": {},
   "source": [
    "## Adding More Documents\n",
    "\n",
    "Let's add another document to see how the knowledge graph grows and evolves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055b697d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional text about graph databases and vector databases\n",
    "graph_db_text = \"\"\"\n",
    "Graph databases are specialized database management systems designed to store and query data \n",
    "represented as graphs. Unlike traditional relational databases that use tables, graph databases \n",
    "use nodes, edges, and properties to represent and store data. Memgraph is a high-performance \n",
    "in-memory graph database that supports the Cypher query language.\n",
    "\n",
    "Vector databases are optimized for storing and querying high-dimensional vectors, which are \n",
    "commonly used in machine learning applications for similarity search and recommendation systems. \n",
    "Popular vector databases include Pinecone, Weaviate, and Chroma.\n",
    "\n",
    "Graph Neural Networks (GNNs) are a class of deep learning models designed to work with \n",
    "graph-structured data. GNNs can learn representations of nodes and edges in graphs, making \n",
    "them useful for tasks like node classification, link prediction, and graph classification.\n",
    "\n",
    "The combination of graph databases and vector databases in RAG systems enables both \n",
    "structured reasoning through knowledge graphs and semantic similarity search through \n",
    "vector embeddings. This hybrid approach provides more comprehensive and accurate \n",
    "information retrieval capabilities.\n",
    "\"\"\"\n",
    "\n",
    "print(\"üìù Adding additional document about graph and vector databases...\")\n",
    "\n",
    "try:\n",
    "    await rag.ainsert(graph_db_text)\n",
    "    print(\"‚úÖ Additional document inserted successfully!\")\n",
    "    print(\"The knowledge graph has been updated with new entities and relationships.\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error during insertion: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb33f2a9",
   "metadata": {},
   "source": [
    "## Query the Enhanced Knowledge Graph\n",
    "\n",
    "Now let's query the enhanced knowledge graph that includes information about both AI/ML and database technologies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641d4492",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query the enhanced knowledge graph\n",
    "enhanced_query = \"How do graph databases like Memgraph support AI and machine learning applications?\"\n",
    "\n",
    "print(f\"üöÄ Enhanced Knowledge Graph Query: {enhanced_query}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "try:\n",
    "    enhanced_response = await rag.aquery(\n",
    "        enhanced_query,\n",
    "        param=QueryParam(mode=\"hybrid\", top_k=30)\n",
    "    )\n",
    "    print(enhanced_response)\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error during enhanced query: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad33cd20",
   "metadata": {},
   "source": [
    "## Cleanup and Finalization\n",
    "\n",
    "Finally, let's properly close the LightRAG instance and clean up resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36861699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup and finalization\n",
    "try:\n",
    "    await rag.finalize_storages()\n",
    "    print(\"‚úÖ LightRAG instance properly finalized.\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error during finalization: {e}\")\n",
    "\n",
    "print(\"\\nüéâ Demo completed successfully!\")\n",
    "print(\"\\nüìù Summary of what we accomplished:\")\n",
    "print(\"   ‚úì Set up LightRAG with Memgraph as graph storage\")\n",
    "print(\"   ‚úì Created knowledge graphs from text documents\")\n",
    "print(\"   ‚úì Performed various types of queries (local, global, hybrid, mix)\")\n",
    "print(\"   ‚úì Added multiple documents to expand the knowledge graph\")\n",
    "print(\"\\nüîó Next Steps:\")\n",
    "print(\"   ‚Ä¢ Explore the knowledge graph in Memgraph Lab\")\n",
    "print(\"   ‚Ä¢ Try adding your own documents\")\n",
    "print(\"   ‚Ä¢ Experiment with different query modes and parameters\")\n",
    "print(\"   ‚Ä¢ Build a complete RAG application using this setup\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52bba134",
   "metadata": {},
   "source": [
    "## Additional Resources and Documentation\n",
    "\n",
    "For more information about LightRAG and Memgraph integration:\n",
    "\n",
    "### LightRAG Resources:\n",
    "- [LightRAG GitHub Repository](https://github.com/HKUDS/LightRAG)\n",
    "\n",
    "### Memgraph Resources:\n",
    "- [Memgraph Documentation](https://memgraph.com/docs)\n",
    "- [Memgraph AI Ecosystem](https://memgraph.com/docs/ai-ecosystem)\n",
    "- [Memgraph's LightRAG integration](https://memgraph.com/docs/ai-ecosystem/integrations#lightrag)\n",
    "\n",
    "### Key Features Demonstrated:\n",
    "1. **Graph Storage**: Using Memgraph as the backend for storing knowledge graphs\n",
    "2. **Entity Extraction**: Automatic extraction of entities and relationships from text\n",
    "3. **Multiple Query Modes**: Local, global, hybrid, and mix query capabilities\n",
    "4. **Workspace Isolation**: Keeping different projects' data separate\n",
    "5. **Real-time Updates**: Adding new documents and updating the knowledge graph\n",
    "\n",
    "### Performance Benefits:\n",
    "- **In-memory Processing**: Memgraph's in-memory architecture for fast graph operations\n",
    "- **Cypher Query Language**: Standard graph query language for complex graph traversals\n",
    "- **Scalability**: Handle large knowledge graphs efficiently\n",
    "- **ACID Compliance**: Reliable data consistency and integrity"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
