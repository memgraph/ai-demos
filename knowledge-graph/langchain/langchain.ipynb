{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChain\n",
    "\n",
    "LangChain is a framework for developing applications powered by large language\n",
    "models (LLMs). Currently, Memgraph's LangChain integration supports\n",
    "creating a knowledge graph from unstructured data and querying with natural\n",
    "language. You can follow the example on [LangChain\n",
    "docs](https://python.langchain.com/docs/integrations/graphs/memgraph/) or go\n",
    "through quick start below.\n",
    "\n",
    "## Installation\n",
    "\n",
    "To install all the required packages, run:\n",
    "\n",
    "```shell\n",
    "pip install langchain langchain-openai neo4j --user\n",
    "```\n",
    "\n",
    "## Environment setup \n",
    "\n",
    "Before you get started, make sure you have [Memgraph](/getting-started) running\n",
    "in the background.\n",
    "\n",
    "Then, instantiate `MemgraphGraph` in your Python code. This object holds the\n",
    "connection to the running Memgraph instance. Make sure to set up all the\n",
    "environment variables properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from langchain_community.chains.graph_qa.memgraph import MemgraphQAChain\n",
    "from langchain_community.graphs import MemgraphGraph\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "url = os.environ.get(\"MEMGRAPH_URI\", \"bolt://localhost:7687\")\n",
    "username = os.environ.get(\"MEMGRAPH_USERNAME\", \"\")\n",
    "password = os.environ.get(\"MEMGRAPH_PASSWORD\", \"\")\n",
    "\n",
    "graph = MemgraphGraph(\n",
    "    url=url, username=username, password=password, refresh_schema=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The `refresh_schema` is initially set to `False` because there is still no data in\n",
    "the database and we want to avoid unnecessary database calls.\n",
    "\n",
    "To interact with the LLM, you must configure it. Here is how you can set API key as an\n",
    "environment variable for OpenAI:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = \"your-key-here\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph construction\n",
    "\n",
    "For the dataset, we'll use the following text about Charles Darwin:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "    Charles Robert Darwin was an English naturalist, geologist, and biologist,\n",
    "    widely known for his contributions to evolutionary biology. His proposition that\n",
    "    all species of life have descended from a common ancestor is now generally\n",
    "    accepted and considered a fundamental scientific concept. In a joint\n",
    "    publication with Alfred Russel Wallace, he introduced his scientific theory that\n",
    "    this branching pattern of evolution resulted from a process he called natural\n",
    "    selection, in which the struggle for existence has a similar effect to the\n",
    "    artificial selection involved in selective breeding. Darwin has been\n",
    "    described as one of the most influential figures in human history and was\n",
    "    honoured by burial in Westminster Abbey.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To construct the graph, first initialize `LLMGraphTransformer` from the desired\n",
    "LLM and convert the document to the graph structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0, model_name=\"gpt-4-turbo\")\n",
    "llm_transformer = LLMGraphTransformer(llm=llm)\n",
    "documents = [Document(page_content=text)]\n",
    "graph_documents = llm_transformer.convert_to_graph_documents(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graph structure in the `GraphDocument` format can be forwarded to the\n",
    "`add_graph_documents()` procedure to import in into Memgraph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure the database is empty\n",
    "graph.query(\"STORAGE MODE IN_MEMORY_ANALYTICAL\")\n",
    "graph.query(\"DROP GRAPH\")\n",
    "graph.query(\"STORAGE MODE IN_MEMORY_TRANSACTIONAL\")\n",
    "\n",
    "# Create KG\n",
    "graph.add_graph_documents(graph_documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `add_graph_documents()` procedure transforms the list of `graph_documents`\n",
    "into appropriate Cypher queries and executes them in Memgraph.\n",
    "\n",
    "In the below image, you can see how the text was transformed into a knowledge\n",
    "graph and stored into Memgraph.\n",
    "\n",
    "![langchain-kg](langchain-kg-creation.png)\n",
    "\n",
    "For additional options, check the [full\n",
    "guide](https://python.langchain.com/docs/integrations/graphs/memgraph/#additional-options)\n",
    "on the LangChain docs. "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
