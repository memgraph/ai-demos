{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell 1: Imports and Setup\n",
    "import openai\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import neo4j\n",
    "from pydantic import BaseModel\n",
    "from typing import Dict, List, Any\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import json\n",
    "import logging\n",
    "import tiktoken\n",
    "\n",
    "# Initialize logging\n",
    "logging.basicConfig(format=\"%(asctime)s - %(levelname)s - %(message)s\", level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Predefined model used.\n",
    "MODEL = {\n",
    "    \"name\": \"gpt-4o-2024-08-06\",\n",
    "    \"context_window\": 128000\n",
    "}\n",
    "\n",
    "# Response format\n",
    "class ToolResponse():\n",
    "    # ... (same as before)\n",
    "\n",
    "# ... (Rest of the class definitions, same as before)\n",
    "\n",
    "\n",
    "# Cell 2: Helper Functions (Descriptions)\n",
    "\n",
    "def classify_the_question(openai_client, user_question: str) -> Dict:\n",
    "    \"\"\"\n",
    "    Classifies the user question into one of the predefined types (Retrieval, Structure, Global, Database).\n",
    "\n",
    "    Uses the OpenAI API to analyze the question and determine its type based on a prompt that provides definitions and examples of each type.\n",
    "\n",
    "    Args:\n",
    "        openai_client: The initialized OpenAI client.\n",
    "        user_question: The question string to classify.\n",
    "\n",
    "    Returns:\n",
    "        A dictionary containing the classified question type and an explanation.\n",
    "    \"\"\"\n",
    "    # ... (code - same as before)\n",
    "\n",
    "def get_schema_string(db_client) -> str:\n",
    "    \"\"\"\n",
    "    Retrieves the database schema information as a formatted string.\n",
    "\n",
    "    Connects to the Memgraph database and retrieves the schema information (nodes, edges, properties, indexes).  Formats this information into a human-readable string.\n",
    "\n",
    "    Args:\n",
    "        db_client: The initialized Neo4j/Memgraph client.\n",
    "\n",
    "    Returns:\n",
    "        A string containing the formatted schema information.\n",
    "    \"\"\"\n",
    "    # ... (code - same as before)\n",
    "\n",
    "def text_to_Cypher(db_client, openai_client, user_question) -> Dict:\n",
    "    \"\"\"\n",
    "    Converts a natural language question into a Cypher query.\n",
    "\n",
    "    Uses the OpenAI API to translate the user's question into a Cypher query that can be executed against the Memgraph database.  Leverages the database schema to generate accurate queries. Includes error correction and retry logic.\n",
    "\n",
    "    Args:\n",
    "        db_client: The initialized Neo4j/Memgraph client.\n",
    "        openai_client: The initialized OpenAI client.\n",
    "        user_question: The question string to translate.\n",
    "\n",
    "    Returns:\n",
    "        A dictionary containing the Cypher query execution status and the results (if successful).\n",
    "    \"\"\"\n",
    "    # ... (code - same as before)\n",
    "\n",
    "def generate_cypher_query(openai_client, prompt_messages):\n",
    "    \"\"\"\n",
    "    Helper function to generate a Cypher query using the OpenAI API.\n",
    "\n",
    "    Args:\n",
    "        openai_client: The initialized OpenAI client.\n",
    "        prompt_messages: The prompt messages for the OpenAI API.\n",
    "\n",
    "    Returns:\n",
    "        The generated Cypher query string.\n",
    "    \"\"\"\n",
    "    # ... (code - same as before)\n",
    "\n",
    "# ... (Descriptions for other helper functions: schema_tool, config_tool, page_rank_choice, page_rank_tool, community_tool, community_prompt, precompute_community_summary, decide_on_structure_parameters, vector_relevance_expansion, find_most_similar_nodes, get_relevant_data, generate_final_response, index_setup, compute_node_embeddings)\n",
    "\n",
    "\n",
    "# Cell 3: Cached Resources\n",
    "\n",
    "@st.cache_resource()\n",
    "def get_openai_client():\n",
    "    \"\"\"\n",
    "    Initializes and caches the OpenAI client.\n",
    "    \"\"\"\n",
    "    return openai.OpenAI()\n",
    "\n",
    "@st.cache_resource()\n",
    "def get_db_client():\n",
    "    \"\"\"\n",
    "    Initializes and caches the Memgraph database client.\n",
    "    \"\"\"\n",
    "    return neo4j.GraphDatabase.driver(\"bolt://localhost:7687\", auth=(\"\", \"\"))\n",
    "\n",
    "@st.cache_resource()\n",
    "def preprocess_data(_db_client, _openai_client):\n",
    "    \"\"\"\n",
    "    Preprocesses the data by setting up the vector index and computing node embeddings.\n",
    "\n",
    "    This function is crucial for enabling vector search functionality. It is cached to ensure it runs only once.\n",
    "\n",
    "    Args:\n",
    "        _db_client: The Memgraph database client.\n",
    "        _openai_client: The OpenAI client.\n",
    "\n",
    "    Returns:\n",
    "      A message indicating processing completion.\n",
    "    \"\"\"\n",
    "    # ... (code - same as before)\n",
    "\n",
    "\n",
    "\n",
    "# Cell 4: Tool Selection and Execution\n",
    "\n",
    "def tool_selection_pipe(openai_client, user_question, question_type) -> Dict:\n",
    "  \"\"\"Selects the appropriate tool to answer the user question.\n",
    "\n",
    "  Based on the question type (Retrieval, Structure, Global, Database), this function uses the OpenAI API to choose the most suitable tool (e.g., Cypher, Vector Relevance Expansion, PageRank, Community, Schema, Config) and a backup tool.\n",
    "\n",
    "  Args:\n",
    "      openai_client: The OpenAI client.\n",
    "      user_question: The user's question.\n",
    "      question_type: The classified type of the question.\n",
    "\n",
    "  Returns:\n",
    "      A dictionary containing the first and second tool choices.\n",
    "  \"\"\"\n",
    "  # ... (code - same as before)\n",
    "\n",
    "def tool_execution(tool: str, db_client, openai_client, user_question) -> ToolResponse:\n",
    "    \"\"\"\n",
    "    Executes the specified tool.\n",
    "\n",
    "    This function dispatches the execution to the appropriate tool function (e.g., text_to_Cypher, vector_relevance_expansion, etc.).\n",
    "\n",
    "    Args:\n",
    "        tool: The name of the tool to execute.\n",
    "        db_client: The Memgraph database client.\n",
    "        openai_client: The OpenAI client.\n",
    "        user_question: The user's question.\n",
    "\n",
    "    Returns:\n",
    "        A ToolResponse object containing the status and results of the tool execution.\n",
    "    \"\"\"\n",
    "    # ... (code - same as before)\n",
    "\n",
    "\n",
    "def execute_tool(tool: str, user_question: str, db_client, openai_client) -> ToolResponse:\n",
    "    \"\"\"\n",
    "    Executes a tool and handles potential errors.\n",
    "\n",
    "    This function calls tool_execution and includes a try-except block to handle any exceptions during tool execution.\n",
    "\n",
    "    Args:\n",
    "        tool: The name of the tool to execute.\n",
    "        user_question: The user's question.\n",
    "        db_client: The Memgraph database client.\n",
    "        openai_client: The OpenAI client.\n",
    "\n",
    "    Returns:\n",
    "        A ToolResponse object.\n",
    "    \"\"\"\n",
    "    # ... (code - same as before)\n",
    "\n",
    "# Cell 5: Main Function\n",
    "\n",
    "def main(user_question):\n",
    "    \"\"\"\n",
    "    Main function to orchestrate the GraphRAG pipeline.\n",
    "\n",
    "    This function takes the user question as input, classifies the question type, selects the appropriate tool, executes the tool, and generates the final response.  Prints the steps and results.\n",
    "\n",
    "    Args:\n",
    "        user_question: The user's question string.\n",
    "    \"\"\"\n",
    "    # ... (code - same as before)\n",
    "\n",
    "\n",
    "# Cell 6: Run the pipeline (Example)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    load_dotenv()\n",
    "    os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "    user_question = input(\"Enter your question about the dataset: \")\n",
    "\n",
    "    main(user_question)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
